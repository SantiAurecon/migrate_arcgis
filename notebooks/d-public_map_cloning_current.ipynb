{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T04:40:33.063874700Z",
     "start_time": "2024-02-28T04:40:33.039875200Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import logging, os, re, datetime\n",
    "\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.mapping import WebMap\n",
    "from arcgis.mapping import WebScene\n",
    "from arcgis.features import FeatureLayerCollection\n",
    "from arcgis.features import FeatureLayer\n",
    "from arcgis.features import FeatureSet\n",
    "\n",
    "import time\n",
    "import scripts.portalmanager as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T04:40:56.301831900Z",
     "start_time": "2024-02-28T04:40:33.062876100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to https://ispgeospatial.com/portal/ as Santiago.Patino@aurecongroup.com (role: org_admin)\n",
      "Please sign in to your GIS and paste the code that is obtained below.\n",
      "If a web browser does not automatically open, please navigate to the URL below yourself instead.\n",
      "Opening web browser to navigate to: https://ppgeospatial-dev.aurecongroup.digital/arcgis/sharing/rest/oauth2/authorize?response_type=code&client_id=ynHaDt7Xb3r9drJg&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&state=1i7njGzRH18uiRcukeDRq2ZLYfBxDm&allow_verification=false\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santiago.patino\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ppgeospatial-dev.aurecongroup.digital'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please sign in to your GIS and paste the code that is obtained below.\n",
      "If a web browser does not automatically open, please navigate to the URL below yourself instead.\n",
      "Opening web browser to navigate to: https://ppgeospatial-dev.aurecongroup.digital/arcgis/sharing/rest/oauth2/authorize?response_type=code&client_id=ynHaDt7Xb3r9drJg&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&state=zR8DeOFYWXevmAM1xgtkN2qNyKOXbN&allow_verification=false\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santiago.patino\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ppgeospatial-dev.aurecongroup.digital'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to https://ppgeospatial-dev.aurecongroup.digital/arcgis/home/ as Santiago.Patino@aurecongroup.com (role: org_publisher)\n"
     ]
    }
   ],
   "source": [
    "portals_csv = '../Conf/portal_connect_deets.csv'\n",
    "\n",
    "usr_args_from_gis_alias_name = 'ISP_OAUTH2' # 'Geoportal_DEV' #'ISP_OAUTH2' #'Geoportal_DEV' #\n",
    "usr_args_to_gis_alias_name = 'DIGITAL_DEV' # 'Geoportal_DEV'\n",
    "migration_name = \"ISP_to_DIGITAL_DEV\"  # \"portaldev_to_digital_dev\" #\"ISP_to_DIGITAL_DEV\" #\n",
    "migrate_itemid = '476b7a011eb34f1dad03ae5e76a2dc90'#connect to source and target GIS env\n",
    "\n",
    "today = datetime.datetime.now().strftime('%d%m%Y')\n",
    "data_folder = '../migration_data'\n",
    "source = pm.portal_connect(portals_csv, usr_args_from_gis_alias_name, username=None, auth_type='Pro')\n",
    "target = pm.portal_connect(portals_csv, usr_args_to_gis_alias_name, username=None, auth_type='OAuth 2.0')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "GIS @ https://ispgeospatial.com/portal/ version:10.3",
      "text/html": "GIS @ <a href=\"https://ispgeospatial.com/portal/\">https://ispgeospatial.com/portal/</a>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_gis =source\n",
    "target_gis = target\n",
    "source_gis"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T04:43:11.667353300Z",
     "start_time": "2024-02-28T04:43:11.638949900Z"
    }
   },
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "GIS @ https://ppgeospatial-dev.aurecongroup.digital/arcgis/home/ version:2023.2",
      "text/html": "GIS @ <a href=\"https://ppgeospatial-dev.aurecongroup.digital/arcgis/home/\">https://ppgeospatial-dev.aurecongroup.digital/arcgis/home/</a>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_gis"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T04:42:47.841235900Z",
     "start_time": "2024-02-28T04:42:47.797989300Z"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T04:40:56.337553800Z",
     "start_time": "2024-02-28T04:40:56.318553900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Script Starting at 2024-02-28 14:40:56.319554\n"
     ]
    }
   ],
   "source": [
    "SaveLogsTo = '../Logs'\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logFileName = datetime.datetime.now().strftime('%Y-%m-%d %H-%M-%S')\n",
    "fileHandler = logging.handlers.RotatingFileHandler('{}/{}.log'.format(SaveLogsTo, logFileName), maxBytes=100000, backupCount=5)\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(relativeCreated)d \\n%(filename)s %(module)s %(funcName)s %(lineno)d \\n%(message)s\\n')\n",
    "fileHandler.setFormatter(formatter)\n",
    "logger.addHandler(fileHandler)\n",
    "logger.info('Script Starting at {}'.format(str(datetime.datetime.now())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T04:40:56.361553800Z",
     "start_time": "2024-02-28T04:40:56.334553800Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_capabilities(url, token):\n",
    "    index = url.find('services/')\n",
    "    admin_url = url[:index] + \"admin/\" + url[index:]\n",
    "    cap_update_url = admin_url + \"/updateDefinition\"\n",
    "    json = str(\"{'capabilities': 'Query'}\")\n",
    "    params = {\"token\": token, \"updateDefinition\": json, 'f':'json'}\n",
    "    requests.post(cap_update_url, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T04:40:56.364553600Z",
     "start_time": "2024-02-28T04:40:56.350553600Z"
    }
   },
   "outputs": [],
   "source": [
    "def correct_layer_ids(url, token, ids_from, ids_to):\n",
    "    # CHange user URL to Admin URL\n",
    "    url = url.replace(\"rest/services\",\"admin/services\")\n",
    "    url = url.replace(\"/FeatureServer\",\".FeatureServer\")\n",
    "    # Get the service defintion\n",
    "    payload = {\"token\": token,'f': 'json'}\n",
    "    #head = {\"Content-type\": \"application/json;charset=UTF-8\", \"Accept\": \"text/plain\"}\n",
    "    response = requests.post(url, data = payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        service_defn = response.json()\n",
    "        print(\"Get the service defintion request succeeded\")\n",
    "    else:\n",
    "        print(\"Get the service defintion request failed with status code:\", response.status_code)\n",
    "    # Grab the current deifntion of the layers dictionary\n",
    "    layers = service_defn[\"jsonProperties\"][\"layers\"]\n",
    "    # Reset the layerIds property\n",
    "    service_defn[\"jsonProperties\"][\"layerIds\"] = ids_from\n",
    "    # Create the subsitutue dictionary\n",
    "    new_layers = {}\n",
    "    \n",
    "    # Copy each defintion but assign it to the correct id\n",
    "    for i in range(len(ids_from)):\n",
    "        from_id = ids_from[i]\n",
    "        to_id = ids_to[i]\n",
    "        new_layers[from_id] = layers[to_id]\n",
    "        new_layers[from_id][\"id\"] = int(from_id)\n",
    "    # Assign back to service defintion\n",
    "    service_defn[\"jsonProperties\"][\"layers\"] = new_layers\n",
    "    \n",
    "    # Now update service via edit method\n",
    "    payload = {'token': token, 'f': 'json', \"service\": json.dumps(service_defn)}\n",
    "    #head = {\"Content-type\": \"application/x-www-form-urlencoded\", \"Accept\": \"text/plain\"}\n",
    "    response = requests.post(url+\"/edit\", data = payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(\"Edit layer id request succeeded\")\n",
    "    else:\n",
    "        print(\"Edit layer id request failed with status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T04:40:56.383204300Z",
     "start_time": "2024-02-28T04:40:56.365553700Z"
    }
   },
   "outputs": [],
   "source": [
    "def move_to_folder(itemid, folderid, token):\n",
    "    url = target_gis.url + \"/sharing/rest/content/users/\" + target_gis.properties.user.username + \"/moveItems\"\n",
    "    #url = \"https://air-arcgis.aurecongroup.digital/arcgis/sharing/rest/content/users/aureconairpublisher/moveItems\"\n",
    "    payload = {'token': token, 'f': 'json', 'items': itemid, 'folder': folderid}\n",
    "    response = requests.post(url, data = payload)\n",
    "    if response.status_code == 200:\n",
    "        print(response.json())\n",
    "    else:\n",
    "        print(\"Request failed with status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T04:40:56.393203900Z",
     "start_time": "2024-02-28T04:40:56.378554200Z"
    }
   },
   "outputs": [],
   "source": [
    "def append_data(url, text, token):\n",
    "    print(\"starting append\")\n",
    "    ad_url = url + \"/addFeatures\"\n",
    "    \n",
    "    payload = {'token': token, 'f': 'pjson', 'features': text}\n",
    "    response = requests.post(ad_url, data = payload)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Successfully added features\")\n",
    "    else:\n",
    "        print(\"Added features request failed with status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T04:40:56.411203400Z",
     "start_time": "2024-02-28T04:40:56.393203900Z"
    }
   },
   "outputs": [],
   "source": [
    "def max_record_count(url, token):\n",
    "    # Change user URL to Admin URL\n",
    "    url = url.replace(\"rest/services\",\"admin/services\")\n",
    "    url = url.replace(\"/FeatureServer\",\".FeatureServer\")\n",
    "    # Get the service defintion\n",
    "    payload = {\"token\": token,'f': 'json'}\n",
    "    response = requests.post(url, data = payload)\n",
    "    if response.status_code == 200:\n",
    "        service_defn = response.json()\n",
    "        print(\"Get the service defintion request succeeded\")\n",
    "    else:\n",
    "        print(\"Get the service defintion request failed with status code:\", response.status_code)\n",
    "    # Grab the current deifntion of the layers dictionary\n",
    "    layers = service_defn[\"jsonProperties\"][\"layers\"]\n",
    "    # Reset the maxRecordCount property\n",
    "    service_defn[\"jsonProperties\"][\"maxRecordCount\"] = 2000\n",
    "    for layer in layers:\n",
    "        print(layer)\n",
    "        layers[layer]['maxRecordCount'] = 2000\n",
    "    \n",
    "    # Now update service via edit method\n",
    "    payload = {'token': token, 'f': 'json', \"service\": json.dumps(service_defn)}\n",
    "    response = requests.post(url+\"/edit\", data = payload)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Edit layer maxRecordCount request succeeded\")\n",
    "    else:\n",
    "        print(\"Edit layer maxRecordCount request failed with status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T04:40:56.426203700Z",
     "start_time": "2024-02-28T04:40:56.409203700Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_slpk(url, text, token):\n",
    "    srch_url = url + \"/sharing/rest/search\"\n",
    "    payload = {'token': token, 'f': 'pjson', 'q': text}\n",
    "    response = requests.post(srch_url, data = payload)\n",
    "    slpk_list = []\n",
    "    if response.status_code == 200:\n",
    "        for slpk in response.json()['results']:\n",
    "            if slpk['type'] == \"Scene Package\":\n",
    "                slpk_list.append(slpk['title'])\n",
    "        return slpk_list\n",
    "    \n",
    "    else:\n",
    "        print(\"Request failed with status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T04:40:56.443203900Z",
     "start_time": "2024-02-28T04:40:56.426203700Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_empty_service(svc_name, svc_disc, svc_tags, svc_snippet, svc_keyword):            \n",
    "    create_parameters = {\n",
    "                \"name\": svc_name,\n",
    "                \"description\": svc_disc,\n",
    "                \"capabilities\": \"Editing,Query,Update,Delete\",#need to turn off the editing, update, Delete as final publication function\n",
    "                \"spatialReference\": {\"wkid\": \"102100\"},\n",
    "                \"zDefault\": 0,\n",
    "                \"properties\": {\n",
    "                    \"path\": \"\",\n",
    "                    \"description\": \"\",\n",
    "                    \"copyright\": \"\"\n",
    "                }\n",
    "    }\n",
    "    service_item = target_gis.content.create_service(name = svc_name, \n",
    "                                                     service_type = 'featureService', \n",
    "                                                     create_params = create_parameters, \n",
    "                                                     tags = svc_tags, \n",
    "                                                     snippet = svc_snippet, \n",
    "                                                     item_properties = {'typeKeywords':svc_keyword})\n",
    "    return service_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T04:40:56.457203700Z",
     "start_time": "2024-02-28T04:40:56.445203900Z"
    }
   },
   "outputs": [],
   "source": [
    "def layer_json_prepare (layer_item, rec_start, target_svc, ids_from, ids_to, target_gis):\n",
    "    src_url = layer_item.url\n",
    "    logger.info('start layer url at {}'.format(str(datetime.datetime.now())))\n",
    "    logger.info('layer url is {}'.format(src_url))\n",
    "    src_fl_id = src_url.split(\"/\")[-1]\n",
    "    trg_fl_id = \"/\" + str(rec_start)\n",
    "    print(src_url)\n",
    "    ids_from.append(src_fl_id)\n",
    "    ids_to.append(str(rec_start))\n",
    "    json_str = json.loads(f'{layer_item.properties}')\n",
    "    del json_str['serviceItemId']\n",
    "    del json_str['sourceSpatialReference']\n",
    "    temp_json = {'layers':[]}\n",
    "    temp_json[\"layers\"].append(json_str)\n",
    "    print(\"adding definition\")\n",
    "    logger.info('adding definition at {}'.format(str(datetime.datetime.now())))\n",
    "    target_svc.manager.add_to_definition(temp_json)\n",
    "    time.sleep(10)\n",
    "    new_fl = FeatureLayer(target_svc.url + trg_fl_id, gis = target_gis)\n",
    "    print(\"start to query\")\n",
    "    \n",
    "    src_fl = FeatureLayer(src_url, gis = source_gis)\n",
    "    #src_fset = layer_item.query(\"1=1\")\n",
    "    src_fset = src_fl.query(\"1=1\")\n",
    "    src_fset_df = src_fset.sdf\n",
    "    #print(src_fset_df)\n",
    "    rename = {}\n",
    "    columns = src_fset_df.columns\n",
    "    for column in columns:\n",
    "        #print(column)\n",
    "        if column != \"SHAPE\":\n",
    "            rename[column] = column.lower()#need to be carefull about the definition query, popup etc as final publication function.\n",
    "\n",
    "    src_fset_df.rename(columns = rename, inplace = True)\n",
    "    #print(src_fset_df)\n",
    "    print(src_fset_df.index)\n",
    "    batch_size = 100\n",
    "    batches = [group for _, group in src_fset_df.groupby(src_fset_df.index // batch_size)]\n",
    "    #print(batches)\n",
    "    print(\"starting batching\")\n",
    "    logger.info('starting batching at {}'.format(str(datetime.datetime.now())))\n",
    "    for i, batch_df in enumerate(batches):\n",
    "\n",
    "        #final_fs = FeatureSet.from_dataframe(batch_df.drop(columns=['assessment_date']))\n",
    "        final_fs = FeatureSet.from_dataframe(batch_df)\n",
    "        #print(final_fs.features)\n",
    "        result = new_fl.edit_features(adds = final_fs)\n",
    "        #result = new_fl.edit_features(adds = final_fs, use_global_ids = True)\n",
    "        #time.sleep(0.1)\n",
    "    time.sleep(5)\n",
    "    return ids_from, ids_to\n",
    "    print(\"end batching\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T04:40:56.474203700Z",
     "start_time": "2024-02-28T04:40:56.460203700Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_popup_labels (json_string):\n",
    "\n",
    "    for layer in json_string:\n",
    "        print(layer['id'])\n",
    "        if 'popupInfo' not in layer:\n",
    "            print(\"not in\")\n",
    "        else:\n",
    "            print(\"in\")\n",
    "            #print(layer['popupInfo'])\n",
    "            #layer['popupInfo']['popupElements']:\n",
    "            #print(layer['popupInfo']['fieldInfos'])\n",
    "            if 'popupElements' in layer['popupInfo']:\n",
    "                print (\"has popupElements \")\n",
    "                for field in layer['popupInfo']['popupElements']:\n",
    "                    #print(field)\n",
    "                    if 'fieldInfos' in field:\n",
    "                        field_list = field['fieldInfos']\n",
    "                        print (\"has fieldInfos in popupElements \")\n",
    "                        for fname in field_list:\n",
    "                            #print(fname['fieldName'].lower())\n",
    "\n",
    "                            data = fname['fieldName'].lower().replace(\"shape.starea()\",\t\"SHAPE__Area\").replace(\"shape.stlength()\", \"SHAPE__Length\")\n",
    "                            new_field = {'fieldName':data}\n",
    "                            fname.update(new_field)\n",
    "                            #print (fname)\n",
    "                    else:\n",
    "                        pass\n",
    "                    if 'mediaInfos' in field:\n",
    "                        print (\"has mediaInfos in popupElements \")\n",
    "                        #print(field['mediaInfos'][0]['value']['fields'])\n",
    "                        field_list = field['mediaInfos'][0]['value']['fields']\n",
    "                        data = [l.lower() for l in field_list]\n",
    "                        #print(field_list)\n",
    "                        print(data)\n",
    "                        #print(field['mediaInfos'][0]['value'])\n",
    "                        new_field = {'fields':data}\n",
    "                        #print(new_field)\n",
    "                        field['mediaInfos'][0]['value'].update(new_field)\n",
    "                        #print(field['mediaInfos'][0]['value'])\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "            if 'expressionInfos' in layer['popupInfo']:\n",
    "                print (\"has expressionInfos\")\n",
    "                expressions = layer['popupInfo']['expressionInfos']\n",
    "                if len(expressions) != 0:\n",
    "                    for expression in expressions:\n",
    "                        #print (expression['expression'])\n",
    "                        if expression['expression'].find(\"Shape.STLength()\") != -1 or expression['expression'].find(\"Shape.STArea()\") != -1:\n",
    "                            #print(\"Contains given substring\")\n",
    "                            new_exp = {'expression': expression['expression'].lower().replace(\"shape.starea()\",\"SHAPE__Area\").replace(\"shape.stlength()\", \"SHAPE__Length\")}\n",
    "                            expression.update(new_exp)\n",
    "                            #print(expression)\n",
    "                        else:\n",
    "                            #print(\"Doesn't contains given substring\")\n",
    "                            #print(expression['expression'].lower())\n",
    "                            new_exp = {'expression': expression['expression'].lower()}\n",
    "                            expression.update(new_exp)\n",
    "                            #print(expression)\n",
    "            if 'layerDefinition' in layer: \n",
    "                if 'drawingInfo' in layer['layerDefinition']:\n",
    "                    if 'labelingInfo' in layer['layerDefinition']['drawingInfo']:\n",
    "                        label_info = layer['layerDefinition']['drawingInfo']['labelingInfo']\n",
    "                        for field in label_info:\n",
    "                            print(field)\n",
    "                            if 'labelExpression' in field:\n",
    "                                field['labelExpression'] = field['labelExpression'].lower().replace(\"shape.starea()\",\"SHAPE__Area\").replace(\"shape.stlength()\", \"SHAPE__Length\")\n",
    "                            if 'labelExpressionInfo' in field:\n",
    "                                field['labelExpressionInfo']['expression'] = field['labelExpressionInfo']['expression'].lower().replace(\"shape.starea()\",\"SHAPE__Area\").replace(\"shape.stlength()\", \"SHAPE__Length\")\n",
    "                            \n",
    "\n",
    "    return json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T04:40:56.486203500Z",
     "start_time": "2024-02-28T04:40:56.472204Z"
    }
   },
   "outputs": [],
   "source": [
    "#source_gis.url\n",
    "def related_item_id (scene_lyr_id,url,token):\n",
    "    rel_trace_url = url + \"sharing/rest/content/items/\" + scene_lyr_id + \"/relatedItems\"\n",
    "    print (rel_trace_url)\n",
    "    payload = {'token': token, 'f': 'json', 'relationshipType': \"Service2Data\", 'direction': 'forward'}\n",
    "    response = requests.post(rel_trace_url, data = payload)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Request succeed with status code:\", response.status_code)\n",
    "        return response.json()['relatedItems'][0]['id']\n",
    "    \n",
    "    else:\n",
    "        print(\"Request failed with status code:\", response.status_code)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T04:40:56.505203700Z",
     "start_time": "2024-02-28T04:40:56.488203700Z"
    }
   },
   "outputs": [],
   "source": [
    "#get service id and get service name\n",
    "def get_item_id(url, token):\n",
    "    print(url)\n",
    "    url_elements = url.split(\"/\")\n",
    "    if 'FeatureServer' in url_elements:\n",
    "        index = url.find('FeatureServer/')\n",
    "        svc_url = url[:index] + \"FeatureServer\"\n",
    "        payload = {\"token\": token,'f': 'json'}  \n",
    "        response = requests.post(svc_url, data = payload)\n",
    "        item_id = response.json()[\"serviceItemId\"]\n",
    "        item_service_name = url_elements[-3]\n",
    "        return item_id, item_service_name\n",
    "    elif 'SceneServer' in url_elements:\n",
    "        index = url.find('SceneServer/')\n",
    "        svc_url = url[:index] + \"SceneServer\"\n",
    "        payload = {\"token\": token,'f': 'json'}  \n",
    "        response = requests.post(svc_url, data = payload)\n",
    "        item_id = response.json()[\"serviceItemId\"]\n",
    "        item_service_name = response.json()[\"serviceName\"]\n",
    "        return item_id, item_service_name\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def process_map(source_gis, webmap_itemid):\n",
    "    print(\"-\"*10 + webmap_itemid + \"-\"*10)\n",
    "    print('Map Starting at {}'.format(str(datetime.datetime.now())))\n",
    "    #logger.info('Map ID is {}'.format(str(dair_map_id))\n",
    "    report_rev_id = 1253\n",
    "    report_rev_name = \"_Rev\" + str(report_rev_id)\n",
    "    src_map = source_gis.content.get(webmap_itemid)\n",
    "    src_map_title = src_map.title\n",
    "    src_map_type = src_map.type\n",
    "    src_map_group = src_map.shared_with['groups'][0] \n",
    "    src_map_owner = src_map.owner\n",
    "    src_map_folder_id = src_map.ownerFolder\n",
    "    src_map_group_id = src_map_group.groupid\n",
    "    src_map_group_name = src_map_group.title\n",
    "    src_user = source_gis.users.search(src_map_owner)\n",
    "    src_folders = src_user[0].folders\n",
    "    src_folder_name = [folder for folder in src_folders if src_map_folder_id in folder['id']][0]['title']\n",
    "    print (\"Map title: \" + src_map_title)\n",
    "    print (\"map type: \" + src_map_type)\n",
    "    print (\"owner: \" + src_map_owner)\n",
    "    print (\"folder id: \" + src_map_folder_id)\n",
    "    print (\"folder name: \" + src_folder_name)\n",
    "    print (\"group id: \" + src_map_group_id)\n",
    "    print (\"group name: \" + src_map_group_name)\n",
    "    print (\"publication rev: Rev\" + str(report_rev_id))\n",
    "    if src_map_type == \"Web Map\":\n",
    "        src_wmp = WebMap(src_map)\n",
    "        itemslist = []\n",
    "        item_name_list =[]\n",
    "        for src_layer in src_wmp.layers:\n",
    "            item_id, item_svc_name = get_item_id(src_layer.url, source_gis._con.token)\n",
    "            if item_id not in itemslist:\n",
    "                \n",
    "                itemslist.append(item_id)\n",
    "                item_name_list.append([item_id, item_svc_name])\n",
    "                \n",
    "        #print([*set(itemslist)])\n",
    "        #itemslist_uniq = [*set(itemslist)]\n",
    "        print(item_name_list)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T04:56:06.347658500Z",
     "start_time": "2024-02-28T04:56:06.331657Z"
    }
   },
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------476b7a011eb34f1dad03ae5e76a2dc90----------\n",
      "Map Starting at 2024-02-28 14:56:07.689112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:arcgis.gis._impl._portalpy:Searching users (q=Santiago.Patino@aurecongroup.com accountid:0123456789ABCDEF, start=1, num=100)\n",
      "INFO:arcgis.gis._impl._portalpy:getting user folders and items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map title: test migration map\n",
      "map type: Web Map\n",
      "owner: Santiago.Patino@aurecongroup.com\n",
      "folder id: f0c0316bc625458488a0f6dae13e9c09\n",
      "folder name: test to migrate\n",
      "group id: 70bec880f9bb430f90a0bacd02bb25d8\n",
      "group name: test_migration_content_group\n",
      "publication rev: Rev1253\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PropertyMap' instance has no attribute 'url'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\1\\ipykernel_56472\\3303571611.py\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mwebmap_itemid\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'476b7a011eb34f1dad03ae5e76a2dc90'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mprocess_map\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msource_gis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwebmap_itemid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\1\\ipykernel_56472\\51407253.py\u001B[0m in \u001B[0;36mprocess_map\u001B[1;34m(source_gis, webmap_itemid)\u001B[0m\n\u001B[0;32m     29\u001B[0m         \u001B[0mitem_name_list\u001B[0m \u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0msrc_layer\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msrc_wmp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 31\u001B[1;33m             \u001B[0mitem_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mitem_svc_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_item_id\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc_layer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msource_gis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_con\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoken\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     32\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mitem_id\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mitemslist\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\lib\\site-packages\\arcgis\\_impl\\common\\_mixins.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m     78\u001B[0m         \"\"\"\n\u001B[0;32m     79\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_valid_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 80\u001B[1;33m             raise AttributeError(\n\u001B[0m\u001B[0;32m     81\u001B[0m                 \"'{cls}' instance has no attribute '{name}'\".format(\n\u001B[0;32m     82\u001B[0m                     \u001B[0mcls\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'PropertyMap' instance has no attribute 'url'"
     ]
    }
   ],
   "source": [
    "webmap_itemid = '476b7a011eb34f1dad03ae5e76a2dc90'\n",
    "process_map(source_gis, webmap_itemid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T04:56:09.652867500Z",
     "start_time": "2024-02-28T04:56:07.689112400Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------476b7a011eb34f1dad03ae5e76a2dc90----------\n",
      "Map Starting at 2024-02-28 14:41:06.696012\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\1\\ipykernel_56472\\1938509979.py\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[0msrc_map_title\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msrc_map\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtitle\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[0msrc_map_type\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msrc_map\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m     \u001B[0msrc_map_group\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msrc_map\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshared_with\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'groups'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m     \u001B[0msrc_map_owner\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msrc_map\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mowner\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[0msrc_map_folder_id\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msrc_map\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mownerFolder\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# air_map_list = ['476b7a011eb34f1dad03ae5e76a2dc90']\n",
    "webmap_itemid = '476b7a011eb34f1dad03ae5e76a2dc90'\n",
    "with webmap_itemid :\n",
    "\n",
    "    print(\"-\"*10 + webmap_itemid + \"-\"*10)\n",
    "    print('Map Starting at {}'.format(str(datetime.datetime.now())))\n",
    "    #logger.info('Map ID is {}'.format(str(dair_map_id))\n",
    "    report_rev_id = 1253\n",
    "    report_rev_name = \"_Rev\" + str(report_rev_id)\n",
    "    src_map = source_gis.content.get(webmap_itemid)\n",
    "    src_map_title = src_map.title\n",
    "    src_map_type = src_map.type\n",
    "    src_map_group = src_map.shared_with['groups'][0]\n",
    "    src_map_owner = src_map.owner\n",
    "    src_map_folder_id = src_map.ownerFolder\n",
    "    src_map_group_id = src_map_group.groupid\n",
    "    src_map_group_name = src_map_group.title\n",
    "    src_user = source_gis.users.search(src_map_owner)\n",
    "    src_folders = src_user[0].folders\n",
    "    src_folder_name = [folder for folder in src_folders if src_map_folder_id in folder['id']][0]['title']\n",
    "    print (\"Map title: \" + src_map_title)\n",
    "    print (\"map type: \" + src_map_type)\n",
    "    print (\"owner: \" + src_map_owner)\n",
    "    print (\"folder id: \" + src_map_folder_id)\n",
    "    print (\"folder name: \" + src_folder_name)\n",
    "    print (\"group id: \" + src_map_group_id)\n",
    "    print (\"group name: \" + src_map_group_name)\n",
    "    print (\"publication rev: Rev\" + str(report_rev_id))\n",
    "    #create new webmap or webscene in exhibition tenancy\n",
    "    #webmap use adding function,feature layer using creating service and append json method, webscene use addItem api to make a copy\n",
    "    if src_map_type == \"Web Map\":\n",
    "        src_wmp = WebMap(src_map)\n",
    "        itemslist = []\n",
    "        item_name_list =[]\n",
    "        for src_layer in src_wmp.layers:\n",
    "            item_id, item_svc_name = get_item_id(src_layer.url, source_gis._con.token)\n",
    "            if item_id not in itemslist:\n",
    "                \n",
    "                itemslist.append(item_id)\n",
    "                item_name_list.append([item_id, item_svc_name])\n",
    "                \n",
    "        #print([*set(itemslist)])\n",
    "        #itemslist_uniq = [*set(itemslist)]\n",
    "        print(item_name_list)\n",
    "        for src_item_id in item_name_list:\n",
    "            print(src_item_id)\n",
    "            src_fl = source_gis.content.get(src_item_id[0])\n",
    "            print(src_fl.title)\n",
    "            new_svc_name = src_item_id[1] + report_rev_name\n",
    "            print(new_svc_name)\n",
    "            name_available = target_gis.content.is_service_name_available(service_name = new_svc_name, service_type = 'featureService')\n",
    "            if name_available == True:\n",
    "                print (\"feature layer is not existing, create a new blank service now...\")\n",
    "                source_kw = \"source-\" + src_item_id[0]\n",
    "                empty_service_item = create_empty_service(new_svc_name, src_fl.description, src_fl.tags, src_fl.snippet, source_kw)\n",
    "                print(\"New one has been created...\")\n",
    "\n",
    "\n",
    "                src_flc = FeatureLayerCollection.fromitem(src_fl)\n",
    "                trg_flc = FeatureLayerCollection.fromitem(empty_service_item)\n",
    "                if src_flc.properties.enableZDefaults == True:\n",
    "                    print(\"has z...\")\n",
    "                    update_dict = {\"enableZDefaults\": True}\n",
    "                    trg_flc.manager.update_definition(update_dict)\n",
    "                    print(\"enabled z...\")\n",
    "                else:\n",
    "                    pass\n",
    "                print(\"Start to appending layers...\")\n",
    "                ids_from = []\n",
    "                ids_to = []\n",
    "                rec = -1\n",
    "                for layer in src_fl.layers:\n",
    "                    rec += 1\n",
    "                    ids_from, ids_to = layer_json_prepare (layer, rec, trg_flc, ids_from, ids_to,target_gis)\n",
    "\n",
    "                    print(\"data appended\")\n",
    "                    #print(src_fset)         \n",
    "\n",
    "                print(\"Start correcting layer ids...\")\n",
    "                correct_layer_ids(empty_service_item.url, target_gis._con.token, ids_from, ids_to)\n",
    "                print(\"Correcting layer ids done...\")\n",
    "                print (\"Start updating capability...\")\n",
    "                update_capabilities(empty_service_item.url, target_gis._con.token)\n",
    "                print (\"cloning and updating capability have done...\")\n",
    "                max_record_count(empty_service_item.url, target_gis._con.token)\n",
    "            else:\n",
    "                #empty_service_item = target_gis.content.get('789ff05ffd664cca8d4f8ab9c235c707')\n",
    "                empty_service_item = []\n",
    "                print (\"feature layer is exiting, no proceed to clone\")\n",
    "    elif src_map_type == \"Web Scene\":\n",
    "        print (\"This map is {map_type}, will clone it as new one now...\".format(map_type = src_map_type))\n",
    "\n",
    "        sr_webscene_obj = WebScene(src_map)\n",
    "        sr_webscene_lyrs = sr_webscene_obj['operationalLayers']\n",
    "        proc_list = []\n",
    "        for layer in sr_webscene_lyrs:\n",
    "            item_id, item_svc_name = get_item_id(layer['url'], source_gis._con.token)\n",
    "\n",
    "            if layer['layerType'] == 'ArcGISSceneServiceLayer':\n",
    "                empty_service_item = []\n",
    "\n",
    "\n",
    "                print (\"Scene layer ID : \" + item_id)\n",
    "                print (\"Scene Layer Service Name: \" + item_svc_name)\n",
    "\n",
    "                rel_slpk_id = related_item_id(item_id,source_gis.url,source_gis._con.token)\n",
    "\n",
    "                src_slpk_item = source_gis.content.get(rel_slpk_id)\n",
    "                print (\"SLPK Name: \" + src_slpk_item.title)\n",
    "                new_slpk_name = src_slpk_item.title + report_rev_name\n",
    "\n",
    "                trg_slpk_list = search_slpk(target_gis.url, new_slpk_name, target_gis._con.token)\n",
    "                #print(trg_slpk_list)\n",
    "                if new_slpk_name not in trg_slpk_list:\n",
    "                    print (\"SLPK is not existing, cloning it now\")\n",
    "                    new_slpk_clone = target_gis.content.clone_items(items = [src_slpk_item], folder = src_folder_name, search_existing_items = True, copy_data = True, preserve_item_id = False)\n",
    "                    print (new_slpk_clone[0].id)\n",
    "                    source_kw = \"source-\" + item_id\n",
    "                    new_slpk_properties = {'title': new_slpk_name,'typeKeywords':source_kw}\n",
    "                    new_slpk_clone[0].update(item_properties = new_slpk_properties)\n",
    "                    print (\"slpk cloning is done\")\n",
    "                    print (\"publishing slpk\")\n",
    "                    publish_parameters = {'name':item_svc_name + report_rev_name}\n",
    "                    new_scene_lyr = new_slpk_clone[0].publish(publish_parameters, file_type = \"scenepackage\",\n",
    "                                                     output_type = \"sceneservice\", build_initial_cache = True)\n",
    "\n",
    "                    print (\"new scene layer has published\")\n",
    "                else:\n",
    "                    print (\"SLPK is exiting, no need to clone\")\n",
    "\n",
    "            elif layer['layerType'] == 'ArcGISFeatureLayer':\n",
    "                #item_id = get_item_id(layer['url'], source_gis._con.token)\n",
    "                if item_id not in proc_list:\n",
    "                    print (\"2D Layer ID: \" + item_id)\n",
    "                    print (\"2D Layer Name: \" + item_svc_name)\n",
    "                    src_fl = source_gis.content.get(item_id)\n",
    "                    new_svc_name = item_svc_name + report_rev_name\n",
    "                    name_available = target_gis.content.is_service_name_available(service_name = new_svc_name, service_type = 'featureService')\n",
    "                    if name_available == True:\n",
    "                        source_kw = \"source-\" + item_id                \n",
    "                        empty_service_item = create_empty_service(new_svc_name, src_fl.description, src_fl.tags, src_fl.snippet, source_kw)\n",
    "                        print(\"New one has been created...\")\n",
    "                        src_flc = FeatureLayerCollection.fromitem(src_fl)\n",
    "                        trg_flc = FeatureLayerCollection.fromitem(empty_service_item)\n",
    "                        if src_flc.properties.enableZDefaults == True:\n",
    "                            print(\"has z...\")\n",
    "                            update_dict = {\"enableZDefaults\": True}\n",
    "                            trg_flc.manager.update_definition(update_dict)\n",
    "                            print(\"enabled z...\")\n",
    "                        else:\n",
    "                            pass\n",
    "                        print(\"Start to appending layers...\")\n",
    "                        ids_from = []\n",
    "                        ids_to = []\n",
    "                        rec = -1\n",
    "                        for layer in src_fl.layers:\n",
    "                            rec += 1\n",
    "                            ids_from, ids_to = layer_json_prepare (layer, rec, trg_flc, ids_from, ids_to,target_gis)\n",
    "                            #print(json_str)\n",
    "                            #append_data(new_fl_url,json.dumps(json_body),target_gis._con.token)\n",
    "                            print(\"data appended\")\n",
    "                            #print(src_fset)\n",
    "                        print(ids_from)\n",
    "                        print(ids_to)\n",
    "\n",
    "                        print(\"Appending layers done...\")\n",
    "                        #print(ids_from)\n",
    "                        #print(ids_to)\n",
    "                        print(\"Start correcting layer ids...\")\n",
    "                        correct_layer_ids(empty_service_item.url, target_gis._con.token, ids_from, ids_to)\n",
    "                        print(\"Correcting layer ids done...\")\n",
    "                        print (\"Start updating capability...\")\n",
    "                        update_capabilities(empty_service_item.url, target_gis._con.token)\n",
    "                        print (\"cloning and updating capability have done...\")\n",
    "                        max_record_count(empty_service_item.url, target_gis._con.token)\n",
    "\n",
    "                    else:\n",
    "                        \n",
    "                        empty_service_item = []\n",
    "                        \n",
    "                        print (\"feature layer is exiting, no proceed to clone\")\n",
    "                    proc_list.append(item_id)\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    print(empty_service_item)\n",
    "    #check webmap is existing\n",
    "    new_map_name = src_map_title + report_rev_name\n",
    "    trg_check_wmp = target_gis.content.search(query = src_map.id)\n",
    "    print(len(trg_check_wmp))\n",
    "    if len(trg_check_wmp)!= 0:\n",
    "        print (\"this maps is existing\")\n",
    "        new_item_clone = []\n",
    "    else:\n",
    "        if src_map_type == \"Web Scene\":\n",
    "            new_item_clone = target_gis.content.clone_items(items = [src_map], folder = src_folder_name, search_existing_items = True, preserve_item_id = True)\n",
    "            new_item_clone[0].update(item_properties = {'title':new_map_name})\n",
    "        else:\n",
    "            new_item_clone = target_gis.content.clone_items(items = [src_map], folder = src_folder_name, search_existing_items = True, preserve_item_id = True)\n",
    "            new_item_clone[0].update(item_properties = {'title':new_map_name})\n",
    "\n",
    "\n",
    "    #update map layer urls\n",
    "    if len(trg_check_wmp)== 0:\n",
    "        if src_map_type == \"Web Map\":\n",
    "            wmp_json = new_item_clone[0].get_data()\n",
    "            #print(map_json1)\n",
    "            map_json1 = wmp_json['operationalLayers']\n",
    "            json_str = update_popup_labels(map_json1)\n",
    "            item_properties = {\"text\": json.dumps(wmp_json)}\n",
    "            new_item_clone[0].update(item_properties = item_properties)\n",
    "            new_wmp = WebMap(new_item_clone[0])\n",
    "            print(empty_service_item)\n",
    "            if len(empty_service_item) != 0:\n",
    "                for layer in new_wmp.layers:\n",
    "                    #print(layer.url)\n",
    "                    lry_url = layer.url[:layer.url.rfind('/')]\n",
    "                    new_fl_lnk = empty_service_item.url\n",
    "                    new_url = layer.url.replace(lry_url, new_fl_lnk)\n",
    "                    layer.update(url = new_url, itemId = empty_service_item.id)\n",
    "                new_wmp.update()\n",
    "            print(\"New webmap has update \")\n",
    "        elif src_map_type == \"Web Scene\":\n",
    "            webscene_string = WebScene(src_map)\n",
    "            map_json1 = webscene_string['operationalLayers']\n",
    "            json_str = update_popup_labels(map_json1)\n",
    "            for layer in map_json1:\n",
    "                print (layer['url'])\n",
    "                ft_title = layer['url'].split('/')\n",
    "                if layer['layerType'] == 'ArcGISSceneServiceLayer':\n",
    "                    index = layer['url'].find('Hosted/')\n",
    "                    admin_url = layer['url'][:index] + ft_title[6] +'/' + ft_title[7]\n",
    "                    target_url = target_gis.url + \"/rest/services/\"+ ft_title[6] +'/'+ ft_title[7] + report_rev_name\n",
    "                    new_url = layer['url'].replace(admin_url, target_url)\n",
    "                    layer['url'] = new_url\n",
    "                elif layer['layerType'] == 'ArcGISFeatureLayer':\n",
    "                    index = layer['url'].find('services/')\n",
    "                    admin_url = layer['url'][:index] + ft_title[5] + '/' + ft_title[6] +'/'+ft_title[7]\n",
    "                    print (\"test:\" + admin_url)\n",
    "                    target_url = target_gis.url + \"/rest/services/Hosted/\"+ ft_title[7] + report_rev_name\n",
    "                    print (target_url)\n",
    "                    new_url = layer['url'].replace(admin_url, target_url)\n",
    "                    print (new_url)\n",
    "                    layer['url'] = new_url\n",
    "                else:\n",
    "                    pass\n",
    "                print (layer['url'])\n",
    "            #json_str = update_popup_labels(map_json1)\n",
    "            item_properties = {\"text\": json.dumps(webscene_string)}\n",
    "            #print (item_properties)\n",
    "            new_item_clone[0].update(item_properties = item_properties)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    #move item to folder\n",
    "    new_folder = target_gis.content.create_folder(src_folder_name)\n",
    "    trg_user = target_gis.users.search(\"aureconairpublisher\")\n",
    "    print(new_folder)\n",
    "    if new_folder == None:\n",
    "        #print('yes')\n",
    "        trg_folders = trg_user[0].folders\n",
    "        print(trg_folders)\n",
    "        new_folder_id = trg_folders[0]['id']\n",
    "    else:\n",
    "        new_folder_id = new_folder['id']\n",
    "    if len(empty_service_item) != 0:\n",
    "        move_to_folder(empty_service_item.id, new_folder_id, target_gis._con.token)\n",
    "    else:\n",
    "        print(\"no need to move item\")\n",
    "    #creation a group\n",
    "    target_groups = target_gis.groups.search(query = src_map_group_name)\n",
    "    if len(target_groups) == 0:\n",
    "        print (\"Creating new group...\")\n",
    "        new_group = target_gis.groups.create(title = src_map_group_name, tags = \"\", description = \"\", access = \"private\")\n",
    "        print(new_group)\n",
    "        target_group_id = new_group.id\n",
    "        print (\"new group has been created\")\n",
    "    else:\n",
    "        print (\"Group existing. no proceed\")\n",
    "        target_group_id = target_groups[0].id\n",
    "    #share item to group\n",
    "    target_user = target_gis.users.search('aureconairpublisher')[0]\n",
    "    folder_items = target_user.items(folder = src_folder_name)\n",
    "    print(folder_items)\n",
    "    #target_group_id = target_gis.groups.search(query = src_map_group_name)[0]\n",
    "    print(target_group_id)\n",
    "    for item in folder_items:\n",
    "        item.share(org = False, groups = target_group_id)\n",
    "    print (\"items have been shared to the group\")\n",
    "    #checking user from source portal gourp\n",
    "    #usersManager = arcgis.gis.UserManager(target_gis)\n",
    "    search_src_gp = source_gis.groups.search(query='id: ' + src_map_group_id)\n",
    "    print(search_src_gp[0].get_members())\n",
    "    src_user_list = search_src_gp[0].get_members()['users']\n",
    "    src_grp_owner = search_src_gp[0].get_members()['admins']\n",
    "    trg_user_list = target_groups[0].get_members()['users']\n",
    "    for o in src_grp_owner:\n",
    "        src_user_list.append(o)\n",
    "    print(src_user_list)\n",
    "    role_mgr = target_gis.users.roles\n",
    "    org_roles = role_mgr.all()\n",
    "\n",
    "    for role in org_roles:\n",
    "        print(f\"{role.name:25}{role.role_id}\")\n",
    "        if role.name =='Aurecon Air Viewer':\n",
    "            role_id = role.role_id\n",
    "        else:\n",
    "            pass\n",
    "    print(role_id)\n",
    "    #adding users to site\n",
    "    for src_user in src_user_list:\n",
    "        if src_user != 'eia.publisher' and src_user != 'siteadmin' and src_user not in trg_user_list:\n",
    "            #print(src_user)\n",
    "            search_trg_users = target_gis.users.search(query = src_user)\n",
    "            if len(search_trg_users) != 0:\n",
    "                print(search_trg_users[0].username + \"is existing\")\n",
    "                target_groups[0].add_users(search_trg_users[0])\n",
    "                print(\"user added to the group\")\n",
    "\n",
    "            else:\n",
    "                search_src_users = source_gis.users.search(query = src_user)\n",
    "                print(\"create user\" + src_user)\n",
    "                #print(search_src_users[0].idpUsername)\n",
    "                new_user = target_gis.users.create(username = search_src_users[0].username,\n",
    "                                                   password = '',\n",
    "                                                   firstname = search_src_users[0].firstName,\n",
    "                                                   lastname = search_src_users[0].lastName,\n",
    "                                                   email = search_src_users[0].email,\n",
    "                                                   description = search_src_users[0].description,\n",
    "                                                   idp_username = search_src_users[0].idpUsername,\n",
    "                                                   role = role_id,\n",
    "                                                   level = 1,\n",
    "                                                   user_type = 'viewerUT',\n",
    "                                                   provider = 'enterprise')\n",
    "                new_user.update(search_src_users[0].access)\n",
    "                target_groups[0].add_users(new_user)\n",
    "\n",
    "        else:\n",
    "            for trg_user in trg_user_list:\n",
    "                if trg_user != 'eia.publisher' and trg_user != 'siteadmin' and trg_user not in src_user_list:\n",
    "                    target_groups[0].remove_users(trg_user)\n",
    "\n",
    "\n",
    "    print(\"all done\")"
   ],
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-02-28T04:41:07.557374400Z",
     "start_time": "2024-02-28T04:41:06.693023700Z"
    }
   },
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "air_map_list = ['476b7a011eb34f1dad03ae5e76a2dc90']\n",
    "for air_map_id in air_map_list:\n",
    "    print(\"-\"*10 + air_map_id + \"-\"*10)\n",
    "    print('Map Starting at {}'.format(str(datetime.datetime.now())))\n",
    "    #logger.info('Map ID is {}'.format(str(dair_map_id))\n",
    "    report_rev_id = 1253\n",
    "    report_rev_name = \"_Rev\" + str(report_rev_id)\n",
    "    src_map = source_gis.content.get(air_map_id)\n",
    "    src_map_title = src_map.title\n",
    "    src_map_type = src_map.type\n",
    "    src_map_group = src_map.shared_with['groups'][0]\n",
    "    src_map_owner = src_map.owner\n",
    "    src_map_folder_id = src_map.ownerFolder\n",
    "    src_map_group_id = src_map_group.groupid\n",
    "    src_map_group_name = src_map_group.title\n",
    "    src_user = source_gis.users.search(src_map_owner)\n",
    "    src_folders = src_user[0].folders\n",
    "    src_folder_name = [folder for folder in src_folders if src_map_folder_id in folder['id']][0]['title']\n",
    "    print (\"Map title: \" + src_map_title)\n",
    "    print (\"map type: \" + src_map_type)\n",
    "    print (\"owner: \" + src_map_owner)\n",
    "    print (\"folder id: \" + src_map_folder_id)\n",
    "    print (\"folder name: \" + src_folder_name)\n",
    "    print (\"group id: \" + src_map_group_id)\n",
    "    print (\"group name: \" + src_map_group_name)\n",
    "    print (\"publication rev: Rev\" + str(report_rev_id))\n",
    "    #create new webmap or webscene in exhibition tenancy\n",
    "    #webmap use adding function,feature layer using creating service and append json method, webscene use addItem api to make a copy\n",
    "    if src_map_type == \"Web Map\":\n",
    "        src_wmp = WebMap(src_map)\n",
    "        itemslist = []\n",
    "        item_name_list =[]\n",
    "        for src_layer in src_wmp.layers:\n",
    "            item_id, item_svc_name = get_item_id(src_layer.url, source_gis._con.token)\n",
    "            if item_id not in itemslist:\n",
    "                \n",
    "                itemslist.append(item_id)\n",
    "                item_name_list.append([item_id, item_svc_name])\n",
    "                \n",
    "        #print([*set(itemslist)])\n",
    "        #itemslist_uniq = [*set(itemslist)]\n",
    "        print(item_name_list)\n",
    "        for src_item_id in item_name_list:\n",
    "            print(src_item_id)\n",
    "            src_fl = source_gis.content.get(src_item_id[0])\n",
    "            print(src_fl.title)\n",
    "            new_svc_name = src_item_id[1] + report_rev_name\n",
    "            print(new_svc_name)\n",
    "            name_available = target_gis.content.is_service_name_available(service_name = new_svc_name, service_type = 'featureService')\n",
    "            if name_available == True:\n",
    "                print (\"feature layer is not existing, create a new blank service now...\")\n",
    "                source_kw = \"source-\" + src_item_id[0]\n",
    "                empty_service_item = create_empty_service(new_svc_name, src_fl.description, src_fl.tags, src_fl.snippet, source_kw)\n",
    "                print(\"New one has been created...\")\n",
    "\n",
    "\n",
    "                src_flc = FeatureLayerCollection.fromitem(src_fl)\n",
    "                trg_flc = FeatureLayerCollection.fromitem(empty_service_item)\n",
    "                if src_flc.properties.enableZDefaults == True:\n",
    "                    print(\"has z...\")\n",
    "                    update_dict = {\"enableZDefaults\": True}\n",
    "                    trg_flc.manager.update_definition(update_dict)\n",
    "                    print(\"enabled z...\")\n",
    "                else:\n",
    "                    pass\n",
    "                print(\"Start to appending layers...\")\n",
    "                ids_from = []\n",
    "                ids_to = []\n",
    "                rec = -1\n",
    "                for layer in src_fl.layers:\n",
    "                    rec += 1\n",
    "                    ids_from, ids_to = layer_json_prepare (layer, rec, trg_flc, ids_from, ids_to,target_gis)\n",
    "\n",
    "                    print(\"data appended\")\n",
    "                    #print(src_fset)         \n",
    "\n",
    "                print(\"Start correcting layer ids...\")\n",
    "                correct_layer_ids(empty_service_item.url, target_gis._con.token, ids_from, ids_to)\n",
    "                print(\"Correcting layer ids done...\")\n",
    "                print (\"Start updating capability...\")\n",
    "                update_capabilities(empty_service_item.url, target_gis._con.token)\n",
    "                print (\"cloning and updating capability have done...\")\n",
    "                max_record_count(empty_service_item.url, target_gis._con.token)\n",
    "            else:\n",
    "                #empty_service_item = target_gis.content.get('789ff05ffd664cca8d4f8ab9c235c707')\n",
    "                empty_service_item = []\n",
    "                print (\"feature layer is exiting, no proceed to clone\")\n",
    "    elif src_map_type == \"Web Scene\":\n",
    "        print (\"This map is {map_type}, will clone it as new one now...\".format(map_type = src_map_type))\n",
    "\n",
    "        sr_webscene_obj = WebScene(src_map)\n",
    "        sr_webscene_lyrs = sr_webscene_obj['operationalLayers']\n",
    "        proc_list = []\n",
    "        for layer in sr_webscene_lyrs:\n",
    "            item_id, item_svc_name = get_item_id(layer['url'], source_gis._con.token)\n",
    "\n",
    "            if layer['layerType'] == 'ArcGISSceneServiceLayer':\n",
    "                empty_service_item = []\n",
    "\n",
    "\n",
    "                print (\"Scene layer ID : \" + item_id)\n",
    "                print (\"Scene Layer Service Name: \" + item_svc_name)\n",
    "\n",
    "                rel_slpk_id = related_item_id(item_id,source_gis.url,source_gis._con.token)\n",
    "\n",
    "                src_slpk_item = source_gis.content.get(rel_slpk_id)\n",
    "                print (\"SLPK Name: \" + src_slpk_item.title)\n",
    "                new_slpk_name = src_slpk_item.title + report_rev_name\n",
    "\n",
    "                trg_slpk_list = search_slpk(target_gis.url, new_slpk_name, target_gis._con.token)\n",
    "                #print(trg_slpk_list)\n",
    "                if new_slpk_name not in trg_slpk_list:\n",
    "                    print (\"SLPK is not existing, cloning it now\")\n",
    "                    new_slpk_clone = target_gis.content.clone_items(items = [src_slpk_item], folder = src_folder_name, search_existing_items = True, copy_data = True, preserve_item_id = False)\n",
    "                    print (new_slpk_clone[0].id)\n",
    "                    source_kw = \"source-\" + item_id\n",
    "                    new_slpk_properties = {'title': new_slpk_name,'typeKeywords':source_kw}\n",
    "                    new_slpk_clone[0].update(item_properties = new_slpk_properties)\n",
    "                    print (\"slpk cloning is done\")\n",
    "                    print (\"publishing slpk\")\n",
    "                    publish_parameters = {'name':item_svc_name + report_rev_name}\n",
    "                    new_scene_lyr = new_slpk_clone[0].publish(publish_parameters, file_type = \"scenepackage\",\n",
    "                                                     output_type = \"sceneservice\", build_initial_cache = True)\n",
    "\n",
    "                    print (\"new scene layer has published\")\n",
    "                else:\n",
    "                    print (\"SLPK is exiting, no need to clone\")\n",
    "\n",
    "            elif layer['layerType'] == 'ArcGISFeatureLayer':\n",
    "                #item_id = get_item_id(layer['url'], source_gis._con.token)\n",
    "                if item_id not in proc_list:\n",
    "                    print (\"2D Layer ID: \" + item_id)\n",
    "                    print (\"2D Layer Name: \" + item_svc_name)\n",
    "                    src_fl = source_gis.content.get(item_id)\n",
    "                    new_svc_name = item_svc_name + report_rev_name\n",
    "                    name_available = target_gis.content.is_service_name_available(service_name = new_svc_name, service_type = 'featureService')\n",
    "                    if name_available == True:\n",
    "                        source_kw = \"source-\" + item_id                \n",
    "                        empty_service_item = create_empty_service(new_svc_name, src_fl.description, src_fl.tags, src_fl.snippet, source_kw)\n",
    "                        print(\"New one has been created...\")\n",
    "                        src_flc = FeatureLayerCollection.fromitem(src_fl)\n",
    "                        trg_flc = FeatureLayerCollection.fromitem(empty_service_item)\n",
    "                        if src_flc.properties.enableZDefaults == True:\n",
    "                            print(\"has z...\")\n",
    "                            update_dict = {\"enableZDefaults\": True}\n",
    "                            trg_flc.manager.update_definition(update_dict)\n",
    "                            print(\"enabled z...\")\n",
    "                        else:\n",
    "                            pass\n",
    "                        print(\"Start to appending layers...\")\n",
    "                        ids_from = []\n",
    "                        ids_to = []\n",
    "                        rec = -1\n",
    "                        for layer in src_fl.layers:\n",
    "                            rec += 1\n",
    "                            ids_from, ids_to = layer_json_prepare (layer, rec, trg_flc, ids_from, ids_to,target_gis)\n",
    "                            #print(json_str)\n",
    "                            #append_data(new_fl_url,json.dumps(json_body),target_gis._con.token)\n",
    "                            print(\"data appended\")\n",
    "                            #print(src_fset)\n",
    "                        print(ids_from)\n",
    "                        print(ids_to)\n",
    "\n",
    "                        print(\"Appending layers done...\")\n",
    "                        #print(ids_from)\n",
    "                        #print(ids_to)\n",
    "                        print(\"Start correcting layer ids...\")\n",
    "                        correct_layer_ids(empty_service_item.url, target_gis._con.token, ids_from, ids_to)\n",
    "                        print(\"Correcting layer ids done...\")\n",
    "                        print (\"Start updating capability...\")\n",
    "                        update_capabilities(empty_service_item.url, target_gis._con.token)\n",
    "                        print (\"cloning and updating capability have done...\")\n",
    "                        max_record_count(empty_service_item.url, target_gis._con.token)\n",
    "\n",
    "                    else:\n",
    "                        \n",
    "                        empty_service_item = []\n",
    "                        \n",
    "                        print (\"feature layer is exiting, no proceed to clone\")\n",
    "                    proc_list.append(item_id)\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    print(empty_service_item)\n",
    "    #check webmap is existing\n",
    "    new_map_name = src_map_title + report_rev_name\n",
    "    trg_check_wmp = target_gis.content.search(query = src_map.id)\n",
    "    print(len(trg_check_wmp))\n",
    "    if len(trg_check_wmp)!= 0:\n",
    "        print (\"this maps is existing\")\n",
    "        new_item_clone = []\n",
    "    else:\n",
    "        if src_map_type == \"Web Scene\":\n",
    "            new_item_clone = target_gis.content.clone_items(items = [src_map], folder = src_folder_name, search_existing_items = True, preserve_item_id = True)\n",
    "            new_item_clone[0].update(item_properties = {'title':new_map_name})\n",
    "        else:\n",
    "            new_item_clone = target_gis.content.clone_items(items = [src_map], folder = src_folder_name, search_existing_items = True, preserve_item_id = True)\n",
    "            new_item_clone[0].update(item_properties = {'title':new_map_name})\n",
    "\n",
    "\n",
    "    #update map layer urls\n",
    "    if len(trg_check_wmp)== 0:\n",
    "        if src_map_type == \"Web Map\":\n",
    "            wmp_json = new_item_clone[0].get_data()\n",
    "            #print(map_json1)\n",
    "            map_json1 = wmp_json['operationalLayers']\n",
    "            json_str = update_popup_labels(map_json1)\n",
    "            item_properties = {\"text\": json.dumps(wmp_json)}\n",
    "            new_item_clone[0].update(item_properties = item_properties)\n",
    "            new_wmp = WebMap(new_item_clone[0])\n",
    "            print(empty_service_item)\n",
    "            if len(empty_service_item) != 0:\n",
    "                for layer in new_wmp.layers:\n",
    "                    #print(layer.url)\n",
    "                    lry_url = layer.url[:layer.url.rfind('/')]\n",
    "                    new_fl_lnk = empty_service_item.url\n",
    "                    new_url = layer.url.replace(lry_url, new_fl_lnk)\n",
    "                    layer.update(url = new_url, itemId = empty_service_item.id)\n",
    "                new_wmp.update()\n",
    "            print(\"New webmap has update \")\n",
    "        elif src_map_type == \"Web Scene\":\n",
    "            webscene_string = WebScene(src_map)\n",
    "            map_json1 = webscene_string['operationalLayers']\n",
    "            json_str = update_popup_labels(map_json1)\n",
    "            for layer in map_json1:\n",
    "                print (layer['url'])\n",
    "                ft_title = layer['url'].split('/')\n",
    "                if layer['layerType'] == 'ArcGISSceneServiceLayer':\n",
    "                    index = layer['url'].find('Hosted/')\n",
    "                    admin_url = layer['url'][:index] + ft_title[6] +'/' + ft_title[7]\n",
    "                    target_url = target_gis.url + \"/rest/services/\"+ ft_title[6] +'/'+ ft_title[7] + report_rev_name\n",
    "                    new_url = layer['url'].replace(admin_url, target_url)\n",
    "                    layer['url'] = new_url\n",
    "                elif layer['layerType'] == 'ArcGISFeatureLayer':\n",
    "                    index = layer['url'].find('services/')\n",
    "                    admin_url = layer['url'][:index] + ft_title[5] + '/' + ft_title[6] +'/'+ft_title[7]\n",
    "                    print (\"test:\" + admin_url)\n",
    "                    target_url = target_gis.url + \"/rest/services/Hosted/\"+ ft_title[7] + report_rev_name\n",
    "                    print (target_url)\n",
    "                    new_url = layer['url'].replace(admin_url, target_url)\n",
    "                    print (new_url)\n",
    "                    layer['url'] = new_url\n",
    "                else:\n",
    "                    pass\n",
    "                print (layer['url'])\n",
    "            #json_str = update_popup_labels(map_json1)\n",
    "            item_properties = {\"text\": json.dumps(webscene_string)}\n",
    "            #print (item_properties)\n",
    "            new_item_clone[0].update(item_properties = item_properties)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    #move item to folder\n",
    "    new_folder = target_gis.content.create_folder(src_folder_name)\n",
    "    trg_user = target_gis.users.search(\"aureconairpublisher\")\n",
    "    print(new_folder)\n",
    "    if new_folder == None:\n",
    "        #print('yes')\n",
    "        trg_folders = trg_user[0].folders\n",
    "        print(trg_folders)\n",
    "        new_folder_id = trg_folders[0]['id']\n",
    "    else:\n",
    "        new_folder_id = new_folder['id']\n",
    "    if len(empty_service_item) != 0:\n",
    "        move_to_folder(empty_service_item.id, new_folder_id, target_gis._con.token)\n",
    "    else:\n",
    "        print(\"no need to move item\")\n",
    "    #creation a group\n",
    "    target_groups = target_gis.groups.search(query = src_map_group_name)\n",
    "    if len(target_groups) == 0:\n",
    "        print (\"Creating new group...\")\n",
    "        new_group = target_gis.groups.create(title = src_map_group_name, tags = \"\", description = \"\", access = \"private\")\n",
    "        print(new_group)\n",
    "        target_group_id = new_group.id\n",
    "        print (\"new group has been created\")\n",
    "    else:\n",
    "        print (\"Group existing. no proceed\")\n",
    "        target_group_id = target_groups[0].id\n",
    "    #share item to group\n",
    "    target_user = target_gis.users.search('aureconairpublisher')[0]\n",
    "    folder_items = target_user.items(folder = src_folder_name)\n",
    "    print(folder_items)\n",
    "    #target_group_id = target_gis.groups.search(query = src_map_group_name)[0]\n",
    "    print(target_group_id)\n",
    "    for item in folder_items:\n",
    "        item.share(org = False, groups = target_group_id)\n",
    "    print (\"items have been shared to the group\")\n",
    "    #checking user from source portal gourp\n",
    "    #usersManager = arcgis.gis.UserManager(target_gis)\n",
    "    search_src_gp = source_gis.groups.search(query='id: ' + src_map_group_id)\n",
    "    print(search_src_gp[0].get_members())\n",
    "    src_user_list = search_src_gp[0].get_members()['users']\n",
    "    src_grp_owner = search_src_gp[0].get_members()['admins']\n",
    "    trg_user_list = target_groups[0].get_members()['users']\n",
    "    for o in src_grp_owner:\n",
    "        src_user_list.append(o)\n",
    "    print(src_user_list)\n",
    "    role_mgr = target_gis.users.roles\n",
    "    org_roles = role_mgr.all()\n",
    "\n",
    "    for role in org_roles:\n",
    "        print(f\"{role.name:25}{role.role_id}\")\n",
    "        if role.name =='Aurecon Air Viewer':\n",
    "            role_id = role.role_id\n",
    "        else:\n",
    "            pass\n",
    "    print(role_id)\n",
    "    #adding users to site\n",
    "    for src_user in src_user_list:\n",
    "        if src_user != 'eia.publisher' and src_user != 'siteadmin' and src_user not in trg_user_list:\n",
    "            #print(src_user)\n",
    "            search_trg_users = target_gis.users.search(query = src_user)\n",
    "            if len(search_trg_users) != 0:\n",
    "                print(search_trg_users[0].username + \"is existing\")\n",
    "                target_groups[0].add_users(search_trg_users[0])\n",
    "                print(\"user added to the group\")\n",
    "\n",
    "            else:\n",
    "                search_src_users = source_gis.users.search(query = src_user)\n",
    "                print(\"create user\" + src_user)\n",
    "                #print(search_src_users[0].idpUsername)\n",
    "                new_user = target_gis.users.create(username = search_src_users[0].username,\n",
    "                                                   password = '',\n",
    "                                                   firstname = search_src_users[0].firstName,\n",
    "                                                   lastname = search_src_users[0].lastName,\n",
    "                                                   email = search_src_users[0].email,\n",
    "                                                   description = search_src_users[0].description,\n",
    "                                                   idp_username = search_src_users[0].idpUsername,\n",
    "                                                   role = role_id,\n",
    "                                                   level = 1,\n",
    "                                                   user_type = 'viewerUT',\n",
    "                                                   provider = 'enterprise')\n",
    "                new_user.update(search_src_users[0].access)\n",
    "                target_groups[0].add_users(new_user)\n",
    "\n",
    "        else:\n",
    "            for trg_user in trg_user_list:\n",
    "                if trg_user != 'eia.publisher' and trg_user != 'siteadmin' and trg_user not in src_user_list:\n",
    "                    target_groups[0].remove_users(trg_user)\n",
    "\n",
    "\n",
    "    print(\"all done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:finished at 2023-11-23 13:55:48.215089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "logger.info('finished at {}'.format(str(datetime.datetime.now())))\n",
    "print(\"finished\")"
   ],
   "metadata": {},
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
